## Christopher Brodski
###### Adobe Experience Manager (AEM) Developer with 5 years of experience designing, developing, and implementing enterprise-level web applications.
- Email: cbrodski@gmail.com
- GitHub: [github.com/Brodski](https://github.com/Brodski)
- LinkedIn: [linkedin.com/in/christopher-brodski](https://www.linkedin.com/in/christopher-brodski)

---

**EDUCATION**
- **B.S. Computer Science**
  - Metropolitan State University of Denver
- **B.S. Applied Mathematics**
  - University of Colorado Denver
- **AWS Certified Cloud Practitioner**
  - Acquired: July 2024 
  - Credly badge https://www.credly.com/badges/6dca7d30-79c0-4e74-8396-35c2db85ffc9/public_url

---

**SKILLS**
- **AEM**: 
  - Sites, Assets, Workflows, Templates, Components, Dispatcher / Apache Server, AEM Cloud Manager, Rapid Dev Environments (RDE)
- **Languages**
  - **Advanced:** Java, Python, Javascript / NodeJS
  - **Highly Proficient:** Kotlin, C#
- **Backend**
  - REST API, Java Servlets / Spring Boot, NodeJS
- **Frontend**
  - **Client-Side:** React, HTML / CSS / JavaScript, Browser Extensions
  - **Server-Side:** NodeJS, EJS, Java Server Pages (JSP)
  - **Dev-Tools:** Gulp.js, Webpack, yarn, npm, SASS, ESLint, Bootstrap
- **Database / Storage**
  - S3, SQL, MongoDB
- **Cloud Computing (AWS)**
  - S3, Lambda, API Gateway, CloudFront, Route 53, IAM, CloudWatch, Elastic Beanstalk
- **Dev Ops**
  - **Skilled:** Docker, Terraform
  - **Experienced:** Microservices, Kubernetes, Jenkins
- **Linux Networking**
  - nslookup, dig, ifconfig, netstat, traceroute, curl, vim, awk, grep

---
**WORK HISTORY**
**Senior Java Web Developer**, at Ping Identity
*Sept 2020 - June 2024*
  - **Overview:** 
    - Build and maintain the company website - Ping Identity (www.pingidentity.com)
    - Develop Adobe Experience Manager (AEM) components, templates, and backend services to support a scalable, high-performance web presence. Extend AEM capabilities by integrating AWS services like Lambda to enhance backend functionality.
  - **AEM:**
    - Contributed to the re-architecture of the AEM codebase, updating build files (Gulp & Maven), refining templates, restructuring components entirely to be JSP-base, and how these components interact and reference each other.
    - Developed Groovy scripts for bulk content updates, automated cleanups, and debugging complex site-wide issues.
    - Managed Apache server configurations, implementing custom rewrite rules and advanced regex for request handling and performance optimization.
    - Extensively work with the Jackrabbit Content Repository (JCR) to store, retrieve, and manipulate structured content.
    - Well-versed in using CRXDE Lite for AEM development, including creating and editing JCR nodes, configuring component properties, and troubleshooting repository issues.
    - Programmatically access OSGi settings, and through the web console for debugging and/or during development.
 - **Cloud infrastructure work:**
    - Built endpoints critical to system functionality that operated without failure since deployment. Accomplished this by deploying AWS Lambda endpoints using Terraform and Node.js.
    - Migrated endpoints off of our current cloud service Adobe to AWS instead; designing and implementing the architecture, pipeline, and IaC tool from start to finish. Independently built AWS Lambda functions, API Gateways, and an accompanying GitLab CI/CD pipeline.
    - Dockerized applications for deployment in our cloud environments, Adobe and AWS.
  - **Backend work:** 
    - Built Java servlets to dynamically generate HTML pages and interact with databases via SQL, enabling seamless content rendering and data exchange. Developed automated jobs for content crawling, bulk edits, data validation, and system monitoring.
    - Wrote and designed services that used LLMs (via OpenAI's API) to personalize website content for users. Implemented request batching, response caching, and fallback handling to ensure efficient API usage and content reliability.
    - Experience with Java threading and asynchronous workflows (thread pools, futures). 
    - Experience with Maven build configurations, including lifecycles, module dependency management, and debugging maven dependencies conflicts.
  - **Frontend work:** 
    - Developed modular, reusable UI components with React and JSP for enterprise applications, supporting dynamic content rendering, localization, and API-driven interactions.
    - Frequent updates to frontend development workflow by configuring CI/CD pipelines, automating testing, and optimizing builds with Webpack and Gulp.js.
    - Working knowledge of asset optimization, cache busting (CDN & client-side), Google Tag Manager, preloading strategies, service workers, accessiblity, and performance profiling.
  - **Soft skills** Mentored new employees and interns, facilitating their success, providing technical guidance onboarding and integration into the organization.

**Platform Infrastructure Integration / Automation Engineer**, at Charter Communications
*Dec 2018 - Oct 2019*
  - **Overview:**
    - Part of a DevOps/SRE team, contributing to deployment processes and quality assurance.
  - **Job Duties:**
    - Routinely accessed virtual machines (VMs) via SSH to execute and develop various scripts. Used command-line tools to navigate the internal file system of the VMs to locate log files, view, filter, and analyze logs for troubleshooting and performance monitoring.
    - Developed a Flask/Python-based proxy server to streamline traffic and facilitate data retrieval from a MongoDB database. Added frontend framework with React. 
    - Wrote a Python-based testing tool for quality assurance on a DHCP server cluster, utilizing the hypervisor's API for precise control over both worker and master virtual machines during stress testing.
    - Deployed docker apps, running Telegraf, to gather metrics from the VMs running the DHCP servers. It streamed data into our Splunk server for real-time data analysis. I also created a Splunk dashboard to visualize and examine the data.
    - Helped build a new test environment for an existing project in AWS by redeploying that project at a scaled-down cluster size. This involved researching company documents and working with the team that managed that project; editing configuration files like Terraform, then executing the deployment. 